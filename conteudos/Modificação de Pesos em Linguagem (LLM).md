## ModificaÃ§Ã£o de Pesos em um Grande Modelo de Linguagem (LLM)

Em modelos de linguagem (LLMs), **os pesos (weights)** sÃ£o **os parÃ¢metros que determinam como o modelo transforma entradas em saÃ­das**.  

Modificar os pesos significa **ajustar esses parÃ¢metros para melhorar o desempenho ou adaptar o modelo a tarefas especÃ­ficas**.

## ğŸ§  Como funciona

1. **Entrada (input)**  
   - Exemplo: `"O cÃ©u Ã© ____"`  
   - O modelo tenta prever a prÃ³xima palavra, ex.: `"azul"`.

2. **PrevisÃ£o e cÃ¡lculo de erro**  
   - O modelo gera uma saÃ­da.  
   - Calcula-se a **diferenÃ§a entre a previsÃ£o e a saÃ­da correta** (funÃ§Ã£o de perda).

3. **Backpropagation e otimizaÃ§Ã£o**  
   - A diferenÃ§a gera **gradientes**, indicando como cada peso deve ser ajustado.  
   - **Gradient Descent** (ou variantes, como Adam) ajusta os pesos para reduzir a perda.

## ğŸ”§ MÃ©todos de modificaÃ§Ã£o de pesos em LLMs

| MÃ©todo | DescriÃ§Ã£o | Quando usar |
|--------|-----------|------------|
| **Fine-Tuning Completo (Ajuste Fino)** | Treina um modelo existente com um **conjunto de dados especÃ­fico** para melhorar desempenho em uma tarefa ou domÃ­nio. Ele **altera os pesos internos do modelo**. | Quando hÃ¡ muitos dados e recursos de GPU/CPU disponÃ­veis |
| **LoRA (Low-Rank Adaptation)** | Adiciona **pequenas matrizes** que modificam os efeitos dos pesos originais | Adaptar o modelo a uma tarefa especÃ­fica sem treinar tudo |
| **Prompt Tuning / Prefix Tuning** | Treina **vetores especiais de entrada** que influenciam a saÃ­da, sem alterar pesos originais | Poucos dados ou economia de recursos |
| **Adapters** | Pequenos mÃ³dulos inseridos entre camadas do modelo | PersonalizaÃ§Ã£o sem alterar o modelo principal |

> âš¡ **Resumo:** os pesos sÃ³ mudam atravÃ©s de **backpropagation/otimizaÃ§Ã£o**, seja ajustando o modelo inteiro ou adicionando adaptadores especÃ­ficos.

---

## ğŸ“ˆ Por que isso importa?

- Permite **personalizar o modelo** para tarefas especÃ­ficas.  
- **Reduz tempo de desenvolvimento**, jÃ¡ que o modelo aprende com menos dados ou de forma mais eficiente.  
- MantÃ©m o modelo **flexÃ­vel e escalÃ¡vel**, sem precisar treinar tudo do zero.

---

## ğŸ”— ReferÃªncias

- [Backpropagation e Gradient Descent](https://en.wikipedia.org/wiki/Backpropagation)  
- [Fine-Tuning de LLMs](https://huggingface.co/docs/transformers/training)  
- [LoRA: Low-Rank Adaptation](https://arxiv.org/abs/2106.09685)  
- [Prompt Tuning](https://arxiv.org/abs/2104.08691)
